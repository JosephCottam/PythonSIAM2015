{
 "metadata": {
  "name": "",
  "signature": "sha256:c5c0f1243ad2b16ad0462205d74549390d0bc794b22d8add1a6789ddf28ca9b4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"images/continuum_analytics_logo.png\" \n",
      "                                alt=\"Continuum Logo\",\n",
      "                                align=\"right\",\n",
      "                                width=\"30%\">,\n",
      "\n",
      "`into`\n",
      "======\n",
      "\n",
      "Into migrates data between formats and locations.\n",
      "\n",
      "Before we can use a database we need to move data into it.  The `into` project provides a single consistent interface to move data between formats and between locations.\n",
      "\n",
      "We'll start with local data and eventually move out to remote data.\n",
      "\n",
      "[*into docs*](http://into.readthedocs.org/en/latest/index.html)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Examples\n",
      "\n",
      "\n",
      "Into moves data into a target from a source\n",
      "\n",
      "```python\n",
      ">>> into(target, source)\n",
      "```\n",
      "\n",
      "The target and source can be either a Python object or a string URI.  The following are all valid calls to `into`\n",
      "\n",
      "```python\n",
      ">>> into(pd.DataFrame, 'iris.csv')  # Load CSV file into new DataFrame\n",
      ">>> into('iris.json', my_df)        # Write DataFrame into JSON file\n",
      ">>> into('iris.json', 'iris.csv')   # Migrate data from CSV to JSON\n",
      "```\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Excerise\n",
      "\n",
      "Use `into` to load the `iris.csv` file into a Python `list`, a `np.ndarray`, and a `pd.DataFrame`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from into import into\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "URI Strings\n",
      "-----------\n",
      "\n",
      "Into refers to foreign data either with a Python object like a `sqlalchemy.Table` object for a SQL table, or with a string URI, like `postgresql://hostname::tablename`.\n",
      "\n",
      "URI's often take on the following form\n",
      "\n",
      "    protocol://path-to-resource::path-within-resource\n",
      "    \n",
      "Where `path-to-resource` might point to a file, a database hostname, etc. while `path-within-resource` might refer to a datapath or table name.  Note the two main separators\n",
      "\n",
      "*   `://` separates the protocol on the left (`sqlite`, `mongodb`, `ssh`, `hdfs`, `hive`, ...)\n",
      "*   `::` separates the path within the database on the right (e.g. tablename)\n",
      "\n",
      "[*into docs on uri strings*](http://into.readthedocs.org/en/latest/uri.html)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Examples\n",
      "\n",
      "Here are some example URIs\n",
      "\n",
      "```\n",
      "myfile.json\n",
      "myfiles.*.csv'\n",
      "postgresql://hostname::tablename\n",
      "mongodb://hostname/db::collection\n",
      "ssh://user@host:/path/to/myfile.csv\n",
      "hdfs://user@host:/path/to/*.csv\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "Migrate your CSV file into a table named `iris` in a new SQLite database at `sqlite:///my.db`.  Remember to use the `::` separator and to separate your database name from your table name.\n",
      "\n",
      "[*into docs on SQL*](http://into.readthedocs.org/en/latest/sql.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What kind of object did you get receive as output?  Call `type` on your result."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "We have a MongoDB database waiting for you at the following address\n",
      "\n",
      "    mongodb://ec2-54-159-160-163.compute-1.amazonaws.com/db\n",
      "    \n",
      "Move your newly built SQLite table into a MongoDB collection.  Remember to use `::` to add a name to your collection."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Verify that your data arrived safely by converting your mongo collection into a list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, clearn up and remove your collection from the MongoDB by calling the `drop` function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from into import drop\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How it works\n",
      "------------\n",
      "\n",
      "Into is a network of fast pairwise conversions between pairs of formats.  We when we migrate between two formats we traverse a path of pairwise conversions.\n",
      "\n",
      "We visualize that network below:\n",
      "\n",
      "![](images/conversions.png)\n",
      "\n",
      "Each node represents a data format. Each directed edge represents a function to transform data between two formats. A single call to into may traverse multiple edges and multiple intermediate formats. Red nodes support larger-than-memory data.\n",
      "\n",
      "A single call to into may traverse several intermediate formats calling on several conversion functions.   For example, we when migrate a CSV file to a Mongo database we might take the following route:\n",
      "\n",
      "* Load in to a `DataFrame` (`pandas.read_csv`)\n",
      "* Convert to `np.recarray` (`DataFrame.to_records`)\n",
      "* Then to a Python `Iterator` (`np.ndarray.tolist`)\n",
      "* Finally to Mongo (`pymongo.Collection.insert`)\n",
      "\n",
      "Alternatively we could write a special function that uses MongoDB's native CSV\n",
      "loader and shortcut this entire process with a direct edge `CSV -> Mongo`.\n",
      "\n",
      "These functions are chosen because they are fast, often far faster than converting through a central serialization format.\n",
      "\n",
      "This picture is actually from an older version of `into`, when the graph was still small enough to visualize pleasantly.  See [*into docs*](http://into.readthedocs.org/en/latest/overview.html) for a more updated version."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Remote Data\n",
      "-----------\n",
      "\n",
      "We can interact with remote data in three locations\n",
      "\n",
      "1.  On Amazon's S3 (this will be quick)\n",
      "2.  On a remote machine via `ssh`\n",
      "3.  On the Hadoop File System (HDFS)\n",
      "\n",
      "For most of this we'll wait until we've seen Blaze, briefly we'll use S3.\n",
      "\n",
      "### S3\n",
      "\n",
      "For now, we quickly grab a file from Amazon's `S3`.\n",
      "\n",
      "This example depends on  [`boto`](https://boto.readthedocs.org/en/latest/) to interact with S3.\n",
      "\n",
      "    conda install boto\n",
      "\n",
      "[*into docs on aws*](http://into.readthedocs.org/en/latest/aws.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "into(pd.DataFrame, 's3://nyqpug/tips.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}